import re
import string
from typing import List, Dict, Any

class SmartNLP:
    def __init__(self):
        self.stopwords = {
            '–∏', '–≤', '–≤–æ', '–Ω–µ', '—á—Ç–æ', '–æ–Ω', '–Ω–∞', '—è', '—Å', '—Å–æ', '–∫–∞–∫', '–∞', '—Ç–æ', '–≤—Å–µ', '–æ–Ω–∞', '—Ç–∞–∫', '–µ–≥–æ', '–Ω–æ', '–¥–∞', '—Ç—ã', '–∫', '—É', '–∂–µ', '–≤—ã', '–∑–∞', '–±—ã', '–ø–æ', '—Ç–æ–ª—å–∫–æ', '–µ–µ', '–º–Ω–µ', '–±—ã–ª–æ', '–≤–æ—Ç', '–æ—Ç', '–º–µ–Ω—è', '–µ—â–µ', '–Ω–µ—Ç', '–æ', '–∏–∑', '–µ–º—É', '—Ç–µ–ø–µ—Ä—å', '–∫–æ–≥–¥–∞', '–¥–∞–∂–µ', '–Ω—É', '–≤–¥—Ä—É–≥', '–ª–∏', '–µ—Å–ª–∏', '—É–∂–µ', '–∏–ª–∏', '–Ω–∏', '–±—ã—Ç—å', '–±—ã–ª', '–Ω–µ–≥–æ', '–¥–æ', '–≤–∞—Å', '–Ω–∏–±—É–¥—å', '–æ–ø—è—Ç—å', '—É–∂', '–≤–∞–º', '–≤–µ–¥—å', '—Ç–∞–º', '–ø–æ—Ç–æ–º', '—Å–µ–±—è', '–Ω–∏—á–µ–≥–æ', '–µ–π', '–º–æ–∂–µ—Ç', '–æ–Ω–∏', '—Ç—É—Ç', '–≥–¥–µ', '–µ—Å—Ç—å', '–Ω–∞–¥–æ', '–Ω–µ–π', '–¥–ª—è', '–º—ã', '—Ç–µ–±—è', '–∏—Ö', '—á–µ–º', '–±—ã–ª–∞', '—Å–∞–º', '—á—Ç–æ–±', '–±–µ–∑', '–±—É–¥—Ç–æ', '—á–µ–≥–æ', '—Ä–∞–∑', '—Ç–æ–∂–µ', '—Å–µ–±–µ', '–ø–æ–¥', '–±—É–¥–µ—Ç', '–∂', '—Ç–æ–≥–¥–∞', '–∫—Ç–æ', '—ç—Ç–æ—Ç', '—Ç–æ–≥–æ', '–ø–æ—Ç–æ–º—É', '—ç—Ç–æ–≥–æ', '–∫–∞–∫–æ–π', '—Å–æ–≤—Å–µ–º', '–Ω–∏–º', '–∑–¥–µ—Å—å', '—ç—Ç–æ–º', '–æ–¥–∏–Ω', '–ø–æ—á—Ç–∏', '–º–æ–π', '—Ç–µ–º', '—á—Ç–æ–±—ã', '–Ω–µ–µ', '—Å–µ–π—á–∞—Å', '–±—ã–ª–∏', '–∫—É–¥–∞', '–∑–∞—á–µ–º', '–≤—Å–µ—Ö', '–Ω–∏–∫–æ–≥–¥–∞', '–º–æ–∂–Ω–æ', '–ø—Ä–∏', '–Ω–∞–∫–æ–Ω–µ—Ü', '–¥–≤–∞', '–æ–±', '–¥—Ä—É–≥–æ–π', '—Ö–æ—Ç—å', '–ø–æ—Å–ª–µ', '–Ω–∞–¥', '–±–æ–ª—å—à–µ', '—Ç–æ—Ç', '—á–µ—Ä–µ–∑', '—ç—Ç–∏', '–Ω–∞—Å', '–ø—Ä–æ', '–≤—Å–µ–≥–æ', '–Ω–∏—Ö', '–∫–∞–∫–∞—è', '–º–Ω–æ–≥–æ', '—Ä–∞–∑–≤–µ', '—Ç—Ä–∏', '—ç—Ç—É', '–º–æ—è', '–≤–ø—Ä–æ—á–µ–º', '—Ö–æ—Ä–æ—à–æ', '—Å–≤–æ—é', '—ç—Ç–æ–π', '–ø–µ—Ä–µ–¥', '–∏–Ω–æ–≥–¥–∞', '–ª—É—á—à–µ', '—á—É—Ç—å', '—Ç–æ–º', '–Ω–µ–ª—å–∑—è', '—Ç–∞–∫–æ–π', '–∏–º', '–±–æ–ª–µ–µ', '–≤—Å–µ–≥–¥–∞', '–∫–æ–Ω–µ—á–Ω–æ', '–≤—Å—é', '–º–µ–∂–¥—É'
        }

    def correct_and_normalize(self, text: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ–ø–µ—á–∞—Ç–∫–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç"""
        if not text:
            return ""

        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text = text.lower().strip()

        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text)

        # –ü—Ä–æ—Å—Ç—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç—ã—Ö –æ–ø–µ—á–∞—Ç–æ–∫
        corrections = {
            '—Å–æ–∑–¥–∞–π': ['—Å–æ–∑–¥–∞–π', '—Å–æ–∑–¥–∞—Ç—å', '—Å–¥–µ–ª–∞–π', '—Å–¥–µ–ª–∞—Ç—å'],
            '–∏–≥—Ä–∞': ['–∏–≥—Ä–∞', '–∏–≥—Ä—É', '–∏–≥—Ä—ã'],
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ': ['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '–ø—Ä–∏–ª–æ–∂', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è'],
            '—Å–∞–π—Ç': ['—Å–∞–π—Ç', '—Å–∞–π—Ç—ã', 'website'],
            '–º–æ–±–∏–ª—å–Ω–æ–µ': ['–º–æ–±–∏–ª—å–Ω–æ–µ', '–º–æ–±–∏–ª—å–Ω', 'mobile'],
        }

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        for correct, variants in corrections.items():
            for variant in variants:
                if variant in text and variant != correct:
                    text = text.replace(variant, correct)

        return text

    def extract_keywords(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return []

        # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
        text = text.translate(str.maketrans('', '', string.punctuation))

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        words = text.lower().split()

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        keywords = [word for word in words if word not in self.stopwords and len(word) > 2]

        return keywords

    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        positive_words = ['—Ö–æ—á—É', '–Ω—É–∂–Ω–æ', '—Å–æ–∑–¥–∞–π', '—Å–¥–µ–ª–∞–π', '–æ—Ç–ª–∏—á–Ω–æ', '—Å—É–ø–µ—Ä', '–∫–ª–∞—Å—Å', '–∫—Ä—É—Ç–æ', '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ']
        negative_words = ['–Ω–µ', '–Ω–µ—Ç', '–ø–ª–æ—Ö–æ', '—É–∂–∞—Å–Ω–æ', '–æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ']

        text_lower = text.lower()

        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)

        if positive_count > negative_count:
            sentiment = 'positive'
        elif negative_count > positive_count:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'

        return {
            'sentiment': sentiment,
            'confidence': abs(positive_count - negative_count) / max(len(text.split()), 1),
            'positive_score': positive_count,
            'negative_score': negative_count
        }

    def classify_intent(self, text: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        text_lower = text.lower()

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        if any(word in text_lower for word in ['—Å–æ–∑–¥–∞–π', '—Å–¥–µ–ª–∞–π', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∞–π', '—Ö–æ—á—É —Å–æ–∑–¥–∞—Ç—å']):
            return 'create_app'

        # –í–æ–ø—Ä–æ—Å—ã
        elif any(word in text_lower for word in ['–∫–∞–∫', '—á—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É']):
            return 'question'

        # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
        elif any(word in text_lower for word in ['–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '–¥–æ–±—Ä—ã–π']):
            return 'greeting'

        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        elif any(word in text_lower for word in ['–¥–∞', '—Å–æ–≥–ª–∞—Å–µ–Ω', '–æ–∫', '—Ö–æ—Ä–æ—à–æ']):
            return 'confirmation'

        # –û—Ç—Ä–∏—Ü–∞–Ω–∏–µ
        elif any(word in text_lower for word in ['–Ω–µ—Ç', '–Ω–µ —Å–æ–≥–ª–∞—Å–µ–Ω', '–æ—Ç–º–µ–Ω–∞']):
            return 'rejection'

        return 'general'
import re
import string
from typing import List, Dict, Any

class SmartNLP:
    def __init__(self):
        self.name = "SmartNLP"
        print("üß† SmartNLP –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –°–ª–æ–≤–∞—Ä—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–ª—è —á–∞—Å—Ç—ã—Ö –æ–ø–µ—á–∞—Ç–æ–∫
        self.corrections = {
            "–ø—Ä–µ–≤–µ—Ç": "–ø—Ä–∏–≤–µ—Ç",
            "–ø—Ä–∏–≤–µ—Ç—ã": "–ø—Ä–∏–≤–µ—Ç", 
            "—Å–æ–∑–¥–∞–π": "—Å–æ–∑–¥–∞–π",
            "—Å–¥–µ–ª–π": "—Å–¥–µ–ª–∞–π",
            "–∏–≥—Ä–∞": "–∏–≥—Ä–∞",
            "–ø—Ä–∏–ª–æ–∂–µ–Ω–µ": "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ",
            "—Å–∞–π—Ç": "—Å–∞–π—Ç"
        }
    
    def correct_and_normalize(self, text: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ–ø–µ—á–∞—Ç–∫–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç"""
        if not text:
            return ""
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text.strip())
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –æ–ø–µ—á–∞—Ç–∫–∏
        words = text.split()
        corrected_words = []
        
        for word in words:
            word_lower = word.lower().strip(string.punctuation)
            if word_lower in self.corrections:
                corrected_words.append(self.corrections[word_lower])
            else:
                corrected_words.append(word)
        
        return ' '.join(corrected_words)
    
    def extract_keywords(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"""
        keywords = []
        text_lower = text.lower()
        
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        app_keywords = ["–∏–≥—Ä–∞", "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "—Å–∞–π—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º–∞", "—Å–∏—Å—Ç–µ–º–∞", "–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞"]
        for keyword in app_keywords:
            if keyword in text_lower:
                keywords.append(keyword)
        
        return keywords
    
    def analyze_intent(self, text: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        text_lower = text.lower()
        
        intent = "general"
        confidence = 0.5
        
        if any(word in text_lower for word in ["—Å–æ–∑–¥–∞–π", "—Å–¥–µ–ª–∞–π", "—Ä–∞–∑—Ä–∞–±–æ—Ç–∞–π"]):
            intent = "create_request"
            confidence = 0.9
        elif any(word in text_lower for word in ["–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–¥–æ–±—Ä—ã–π"]):
            intent = "greeting"
            confidence = 0.9
        elif any(word in text_lower for word in ["–ø–æ–º–æ—â—å", "–ø–æ–º–æ–≥–∏", "–Ω–µ –∑–Ω–∞—é"]):
            intent = "help_request"
            confidence = 0.8
        
        return {
            "intent": intent,
            "confidence": confidence,
            "keywords": self.extract_keywords(text)
        }
